[package]
name = "sentient_core"
version = "0.3.0"
edition = "2021"
authors = ["Timothy Bogdala <tdb@animal-machine.com>"]
description = "A terminal interface for chatting with AI using locally hosted large language models."


[dependencies]
# Gotta force 'cc' down to 1.0.83 due to build breaking problems
# $ cargo update -p cc --precise "1.0.83"
llama_cpp_rs = { git = "https://github.com/tbogdala/rust-llama.cpp.git", branch="dev" }
candle-core = { version = "0.4", optional = true }
candle-nn =  { version = "0.4", optional = true }
candle-transformers =  { version = "0.4", optional = true }
anyhow = "1.0.72"
chrono = "0.4.31"
clap = "4.3.19"
crossbeam = { version = "0.8.2", features = ["crossbeam-channel"] }
crossterm = "0.27"
directories = "5.0.1"
log = "0.4.19"
once_cell = "1.18.0"
rand = "0.8.5"
ratatui = "0.26"
regex = "1.9.3"
reqwest = { version = "0.11.22", features = ["blocking"] }
serde = { version="1.0.180", features = ["derive"] }
serde_json = "1.0.107"
serde_yaml = "0.9.25"
simple_logger = { version = "4.2.0", features = ["stderr"] }
tokenizers = { version = "0.15.0", optional = true }
unicode-segmentation = "1.10.1"
unicode-width = "0.1.11"


[features]
default = []

# CUDA backend for the main llamacpp interface
cuda = ["llama_cpp_rs/cuda"]

# Metal backend for the main llamacpp interface
metal = ["llama_cpp_rs/metal"]

# Feature that enables sentence_similarity testing
sentence_similarity = []

# Enables CUDA accellerated sentence_similarity via candle
sentence_similarity_cuda = [
    "sentence_similarity",
    "candle-core/cuda", 
    "candle-core/cudnn", 
    "candle-nn/cuda", 
    "candle-transformers/cuda",
    "tokenizers"
]

# Enables Metal accellerated sentence_similarity via candle
sentence_similarity_metal = [
    "sentence_similarity",
    "candle-core/metal", 
    "candle-nn/metal", 
    "candle-transformers/metal",
    "tokenizers"
]
